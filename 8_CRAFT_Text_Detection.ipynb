{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec12404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from luo import TicToc\n",
    "from skimage import transform\n",
    "from skimage import transform as TR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90ab567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --id 1eAymcrGvjlnGt3amBxXPvmKJODtE34ZD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb68f736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae5560",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a4c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_center(points):\n",
    "    \"\"\"\n",
    "        support two input ways\n",
    "        4 points: x1, y1, x2, y2, x3, y3, x4, y4\n",
    "        2 points: lt_x1, lt_y1, rd_x2, rd_y2\n",
    "    \"\"\"\n",
    "    if len(points) == 4:\n",
    "        x1, y1, x2, y2 = points\n",
    "        x3, y3, x4, y4 = x2, y1, x1, y2\n",
    "    elif len(points) == 8:\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4 = points\n",
    "    else:\n",
    "        raise (\"please input 2 points or 4 points, check it\")\n",
    "    center_x = round((x1 + x2 + x3 + x4) / 4)\n",
    "    center_y = round((y1 + y2 + y3 + y4) / 4)\n",
    "    return center_x, center_y, x1, y1, x3, y3, x2, y2, x4, y4\n",
    "\n",
    "\n",
    "def triangle_center(points):\n",
    "    if len(points) == 6:\n",
    "        x1, y1, x2, y2, x3, y3 = points\n",
    "    else:\n",
    "        raise (\"please input 3 points, check it\")\n",
    "    center_x = round((x1 + x2 + x3) / 3)\n",
    "    center_y = round((y1 + y2 + y3) / 3)\n",
    "    return center_x, center_y\n",
    "\n",
    "\n",
    "def sorted_boxes(boxes):\n",
    "    # sorted by the left top point's x location\n",
    "    boxes = sorted(boxes, key=lambda box: box[0])\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def create_affine_boxes(boxes):\n",
    "    affine_boxes = []\n",
    "    if len(boxes) == 1:\n",
    "        return affine_boxes\n",
    "    for boxes_1, boxes_2 in zip(boxes[:-1], boxes[1:]):\n",
    "        center_x1, center_y1, x1, y1, x3, y3, x2, y2, x4, y4 = box_center(boxes_1)\n",
    "        points_x1, points_y1 = triangle_center([center_x1, center_y1, x1, y1, x2, y2])\n",
    "        points_x2, points_y2 = triangle_center([center_x1, center_y1, x3, y3, x4, y4])\n",
    "        center_x2, center_y2, x1, y1, x3, y3, x2, y2, x4, y4 = box_center(boxes_2)\n",
    "        points_x3, points_y3 = triangle_center([center_x2, center_y2, x1, y1, x2, y2])\n",
    "        points_x4, points_y4 = triangle_center([center_x2, center_y2, x3, y3, x4, y4])\n",
    "        affine_boxes.append([points_x1, points_y1, points_x3, points_y3, points_x4, points_y4, points_x2, points_y2, ])\n",
    "    return affine_boxes\n",
    "\n",
    "\n",
    "def find_min_rectangle(points):\n",
    "    if len(points) == 4:\n",
    "        x1, y1, x2, y2 = points\n",
    "        x3, y3, x4, y4 = x2, y1, x1, y2\n",
    "    elif len(points) == 8:\n",
    "        x1, y1, x2, y2, x3, y3, x4, y4 = points\n",
    "    else:\n",
    "        raise (\"please input 2 points or 4 points, check it\")\n",
    "    lt_x = min(x1, x2, x3, x4)\n",
    "    lt_y = min(y1, y2, y3, y4)\n",
    "    rd_x = max(x1, x2, x3, x4)\n",
    "    rd_y = max(y1, y2, y3, y4)\n",
    "    return np.float32([[lt_x, lt_y], [rd_x, lt_y], [rd_x, rd_y], [lt_x, rd_y]]), int(rd_x - lt_x), int(rd_y - lt_y)\n",
    "\n",
    "\n",
    "def gaussian_kernel_2d_opencv(kernel_size=(3, 3)):\n",
    "    ky = cv2.getGaussianKernel(kernel_size[0], int(kernel_size[0] / 4))\n",
    "    kx = cv2.getGaussianKernel(kernel_size[1], int(kernel_size[1] / 4))\n",
    "    return np.multiply(ky, np.transpose(kx))\n",
    "\n",
    "\n",
    "def aff_gaussian(gaussian, box, pts, deta_x, deta_y):\n",
    "    de_x, de_y = box[0]\n",
    "    box = box - [de_x, de_y]\n",
    "    pts = pts - [de_x, de_y]\n",
    "    M = cv2.getPerspectiveTransform(box, pts)\n",
    "    res = cv2.warpPerspective(gaussian, M, (deta_y, deta_x))\n",
    "    return res\n",
    "\n",
    "\n",
    "def rotate(angle, image):\n",
    "    h, w = image.shape[1:]\n",
    "    image = image.transpose((1, 2, 0))\n",
    "\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    image = cv2.warpAffine(image, M, (w, h))\n",
    "    image = image.transpose((2, 0, 1))\n",
    "\n",
    "    return image, M\n",
    "\n",
    "\n",
    "def rotate_point(M, x, y):\n",
    "    point = np.array([x, y, 1])\n",
    "    x, y = M.dot(point)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c96738dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, char_gt, aff_gt = sample[\"image\"], sample[\"char_gt\"], sample[\"aff_gt\"]\n",
    "        h, w = image.shape[1:]\n",
    "        new_h, new_w = self.output_size\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[:, top:top + new_h, left:left + new_w]\n",
    "        char_gt = char_gt[top:top + new_h, left:left + new_w]\n",
    "        aff_gt = aff_gt[top:top + new_h, left:left + new_w]\n",
    "\n",
    "        sample = {'image': image, 'char_gt': char_gt, 'aff_gt': aff_gt}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Rescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, char_gt, aff_gt = sample[\"image\"], sample[\"char_gt\"], sample[\"aff_gt\"]\n",
    "        h, w = image.shape[1:]\n",
    "        new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        image = transform.resize(image, (new_h, new_w))\n",
    "        char_gt = transform.resize(char_gt, (new_h, new_w))\n",
    "        aff_gt = transform.resize(aff_gt, (new_h, new_w))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample = {'image': image, 'char_gt': char_gt, 'aff_gt': aff_gt}\n",
    "        return sample\n",
    "\n",
    "\n",
    "class RedomRescale(object):\n",
    "    def __init__(self, output_size_list):\n",
    "        self.output_size_list\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        length = len(self.output_size_list)\n",
    "        idx = random.randint(0, length - 1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Random_change(object):\n",
    "    def __init__(self, random_bright, random_swap, random_contrast, random_saturation, random_hue):\n",
    "        self.random_bright = random_bright\n",
    "        self.random_swap = random_swap\n",
    "        self.random_contrast = random_contrast\n",
    "        self.random_saturation = random_saturation\n",
    "        self.random_hue = random_hue\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, char_gt, aff_gt = sample[\"image\"], sample[\"char_gt\"], sample[\"aff_gt\"]\n",
    "        if random.random() < self.random_bright:\n",
    "            delta = random.uniform(-32, 32)\n",
    "            image += delta\n",
    "            image = image.clip(min=0, max=255)\n",
    "\n",
    "        perms = ((0, 1, 2), (0, 2, 1), (1, 0, 2), (1, 2, 0), (2, 0, 1), (2, 1, 0))\n",
    "        if random.random() < self.random_swap:\n",
    "            swap = perms[random.randrange(0, len(perms))]\n",
    "            image = image[swap, :, :]\n",
    "\n",
    "        if random.random() < self.random_contrast:\n",
    "            alpha = random.uniform(0.5, 1.5)\n",
    "            image *= alpha\n",
    "            image = image.clip(min=0, max=255)\n",
    "\n",
    "        if random.random() < self.random_saturation:\n",
    "            image[1, :, :] *= random.uniform(0.5, 1.5)\n",
    "\n",
    "        if random.random() < self.random_hue:\n",
    "            image[0, :, :] += random.uniform(-18.0, 18.0)\n",
    "            image[0, :, :][image[0, :, :] > 360.0] -= 360.0\n",
    "            image[0, :, :][image[0, :, :] < 0.0] += 360.0\n",
    "\n",
    "        sample = {'image': image, 'char_gt': char_gt, 'aff_gt': aff_gt}\n",
    "        return sample\n",
    "\n",
    "\n",
    "def random_resize_collate(batch):\n",
    "    size = (320, 416, 480, 576, 640)\n",
    "    random_size = size[random.randint(0, 4)]\n",
    "    half_size = int(random_size / 2)\n",
    "    images = []\n",
    "    char_gts = []\n",
    "    aff_gts = []\n",
    "    for data in batch:\n",
    "        images.append(data[\"image\"])\n",
    "        char_gts.append(data[\"char_gt\"])\n",
    "        aff_gts.append(data[\"aff_gt\"])\n",
    "\n",
    "    tr_images = []\n",
    "    tr_char_gts = []\n",
    "    tr_aff_gts = []\n",
    "    for image, char_gt, aff_gt in zip(images, char_gts, aff_gts):\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        image = transform.resize(image, (random_size, random_size))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        char_gt = transform.resize(char_gt, (half_size, half_size))\n",
    "        aff_gt = transform.resize(aff_gt, (half_size, half_size))\n",
    "        tr_images.append(torch.from_numpy(image))\n",
    "        tr_char_gts.append(torch.from_numpy(char_gt))\n",
    "        tr_aff_gts.append(torch.from_numpy(aff_gt))\n",
    "    tr_images = torch.stack(tr_images, 0)\n",
    "    tr_char_gts = torch.stack(tr_char_gts, 0)\n",
    "    tr_aff_gts = torch.stack(tr_aff_gts, 0)\n",
    "    sample = {\n",
    "        'image': tr_images,\n",
    "        'char_gt': tr_char_gts,\n",
    "        'aff_gt': tr_aff_gts,\n",
    "    }\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646451e",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcff59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthText(Dataset):\n",
    "    def __init__(self, data_dir_path=None, random_rote_rate=None, data_file_name=None, istrain=True,\n",
    "                 image_size=(3, 640, 640), down_rate=2, transform=None):\n",
    "        # check data path\n",
    "        if data_dir_path is None:\n",
    "            data_dir_path = \"./data/SynthText\"\n",
    "        if data_file_name is None:\n",
    "            data_file_name = \"gt.mat\"\n",
    "        self.data_dir_path = data_dir_path\n",
    "        self.data_file_name = data_file_name\n",
    "        print(\"load data, please wait a moment...\")\n",
    "\n",
    "        self.agt = scio.loadmat(os.path.join(self.data_dir_path, self.data_file_name))\n",
    "        self.istrain = istrain\n",
    "        self.gt = {}\n",
    "        if istrain:\n",
    "            self.gt[\"txt\"] = self.agt[\"txt\"][0][:-1][:-100]\n",
    "            self.gt[\"imnames\"] = self.agt[\"imnames\"][0][:-100]\n",
    "            self.gt[\"charBB\"] = self.agt[\"charBB\"][0][:-100]\n",
    "            self.gt[\"wordBB\"] = self.agt[\"wordBB\"][0][:-100]\n",
    "        else:\n",
    "            self.gt[\"txt\"] = self.agt[\"txt\"][0][-100:]\n",
    "            self.gt[\"imnames\"] = self.agt[\"imnames\"][0][-100:]\n",
    "            self.gt[\"charBB\"] = self.agt[\"charBB\"][0][-100:]\n",
    "            self.gt[\"wordBB\"] = self.agt[\"wordBB\"][0][-100:]\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.down_rate = down_rate\n",
    "        self.transform = transform\n",
    "        self.random_rote_rate = random_rote_rate\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.gt[\"txt\"].shape[0]\n",
    "\n",
    "    def resize(self, image, char_label, word_laebl):\n",
    "        w, h = image.size\n",
    "        img = np.zeros(self.image_size)\n",
    "        rate = self.image_size[2] / self.image_size[1]\n",
    "        rate_pic = w / h\n",
    "\n",
    "        if rate_pic > rate:\n",
    "            resize_h = int(self.image_size[2] / rate_pic)\n",
    "            image = image.resize((self.image_size[2], resize_h), Image.ANTIALIAS)\n",
    "            image = np.array(image)\n",
    "            if self.image_size[0] == 3:\n",
    "                if len(image.shape) == 2:\n",
    "                    image = np.tile(image, (3, 1, 1))\n",
    "                else:\n",
    "                    image = image.transpose((2, 0, 1))\n",
    "\n",
    "            img[:, :resize_h, :] = image\n",
    "            char_label = char_label * (resize_h / h)\n",
    "            word_laebl = word_laebl * (resize_h / h)\n",
    "        else:\n",
    "            resize_w = int(rate_pic * self.image_size[1])\n",
    "            image = image.resize((resize_w, self.image_size[1]), Image.ANTIALIAS)\n",
    "            image = np.array(image)\n",
    "            if self.image_size[0] == 3:\n",
    "                if len(image.shape) == 2:\n",
    "                    image = np.tile(image, (3, 1, 1))\n",
    "                else:\n",
    "                    image = image.transpose((2, 0, 1))\n",
    "\n",
    "            img[:, :, :resize_w] = np.array(image)\n",
    "            char_label = char_label * (resize_w / w)\n",
    "            word_laebl = word_laebl * (resize_w / w)\n",
    "        return img, char_label, word_laebl\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.gt[\"imnames\"][idx]\n",
    "        img_name = img_name.replace(\" \", \"\")\n",
    "        image = Image.open(os.path.join(self.data_dir_path, img_name))\n",
    "        char_label = self.gt[\"charBB\"][idx].transpose(2, 1, 0)\n",
    "        if len(self.gt[\"wordBB\"][idx].shape) == 3:\n",
    "            word_laebl = self.gt[\"wordBB\"][idx].transpose(2, 1, 0)\n",
    "        else:\n",
    "            word_laebl = self.gt[\"wordBB\"][idx].transpose(1, 0)[np.newaxis, :]\n",
    "        txt_label = self.gt[\"txt\"][idx]\n",
    "\n",
    "        img, char_label, word_laebl = self.resize(image, char_label, word_laebl)\n",
    "\n",
    "        if self.random_rote_rate:\n",
    "            angel = random.randint(0 - self.random_rote_rate, self.random_rote_rate)\n",
    "            img, M = rotate(angel, img)\n",
    "\n",
    "        char_gt = np.zeros((int(self.image_size[1]), int(self.image_size[2])))\n",
    "        aff_gt = np.zeros((int(self.image_size[1]), int(self.image_size[2])))\n",
    "\n",
    "        line_boxes = []\n",
    "        char_index = 0\n",
    "        word_index = 0\n",
    "        for txt in txt_label:\n",
    "            for strings in txt.split(\"\\n\"):\n",
    "                for string in strings.split(\" \"):\n",
    "                    if string == \"\":\n",
    "                        continue\n",
    "                    char_boxes = []\n",
    "                    for char in string:\n",
    "                        x0, y0 = char_label[char_index][0]\n",
    "                        x1, y1 = char_label[char_index][1]\n",
    "                        x2, y2 = char_label[char_index][2]\n",
    "                        x3, y3 = char_label[char_index][3]\n",
    "\n",
    "                        if self.random_rote_rate:\n",
    "                            x0, y0 = rotate_point(M, x0, y0)\n",
    "                            x1, y1 = rotate_point(M, x1, y1)\n",
    "                            x2, y2 = rotate_point(M, x2, y2)\n",
    "                            x3, y3 = rotate_point(M, x3, y3)\n",
    "\n",
    "                        x0, y0, x1, y1, x2, y2, x3, y3 = int(round(x0)), int(round(y0)), int(round(x1)), int(\n",
    "                            round(y1)), int(round(x2)), int(round(y2)), int(round(x3)), int(round(y3))\n",
    "                        char_boxes.append([x0, y0, x1, y1, x2, y2, x3, y3])\n",
    "                        box, deta_x, deta_y = find_min_rectangle([x0, y0, x1, y1, x2, y2, x3, y3])\n",
    "                        if deta_x <= 0 or deta_x >= self.image_size[2] or deta_y <= 0 or deta_y >= self.image_size[1]:\n",
    "                            # print(idx, deta_x, deta_y)\n",
    "                            char_index += 1\n",
    "                            continue\n",
    "                        try:\n",
    "                            gaussian = gaussian_kernel_2d_opencv(kernel_size=(deta_y, deta_x))\n",
    "                            pts = np.float32([[x0, y0], [x1, y1], [x2, y2], [x3, y3]])\n",
    "                            res = aff_gaussian(gaussian, box, pts, deta_y, deta_x)\n",
    "                        except:\n",
    "                            char_index += 1\n",
    "                            continue\n",
    "\n",
    "                        min_x = min(x0, x1, x2, x3)\n",
    "                        min_y = min(y0, y1, y2, y3)\n",
    "\n",
    "                        if np.max(res) > 0:\n",
    "                            mx = 1 / np.max(res)\n",
    "                            res = mx * res\n",
    "                            gh, gw = res.shape\n",
    "                            for th in range(gh):\n",
    "                                for tw in range(gw):\n",
    "                                    if 0 < min_y + th < char_gt.shape[0] and 0 < min_x + tw < char_gt.shape[1]:\n",
    "                                        try:\n",
    "                                            char_gt[min_y + th, min_x + tw] = max(char_gt[min_y + th, min_x + tw],\n",
    "                                                                                  res[th, tw])\n",
    "                                        except:\n",
    "                                            print(idx, min_y + th, min_x + tw)\n",
    "\n",
    "                        char_index += 1\n",
    "                    word_index += 1\n",
    "                    line_boxes.append(char_boxes)\n",
    "        affine_boxes = []\n",
    "        for char_boxes in line_boxes:\n",
    "            affine_boxes.extend(create_affine_boxes(char_boxes))\n",
    "            for points in affine_boxes:\n",
    "                x0, y0, x1, y1, x2, y2, x3, y3 = points[0], points[1], points[2], points[3], points[4], points[5], \\\n",
    "                                                 points[6], points[7]\n",
    "                box, deta_x, deta_y = find_min_rectangle(points)\n",
    "                if deta_x <= 0 or deta_x >= self.image_size[2] or deta_y <= 0 or deta_y >= self.image_size[1]:\n",
    "                    continue\n",
    "                try:\n",
    "                    gaussian = gaussian_kernel_2d_opencv(kernel_size=(deta_y, deta_x))\n",
    "                    pts = np.float32([[x0, y0], [x1, y1], [x2, y2], [x3, y3]])\n",
    "                    res = aff_gaussian(gaussian, box, pts, deta_y, deta_x)\n",
    "                except:\n",
    "                    continue\n",
    "                min_x = min(x0, x1, x2, x3)\n",
    "                min_y = min(y0, y1, y2, y3)\n",
    "\n",
    "                if np.max(res) > 0:\n",
    "                    mx = 1 / np.max(res)\n",
    "                    res = mx * res\n",
    "                    gh, gw = res.shape\n",
    "                    for th in range(gh):\n",
    "                        for tw in range(gw):\n",
    "                            if 0 < min_y + th < aff_gt.shape[0] and 0 < min_x + tw < aff_gt.shape[1]:\n",
    "                                try:\n",
    "                                    aff_gt[min_y + th, min_x + tw] = max(aff_gt[min_y + th, min_x + tw], res[th, tw])\n",
    "                                except:\n",
    "                                    print(idx, min_y + th, min_x + tw)\n",
    "        sample = {\n",
    "            'image': img,\n",
    "            'char_gt': char_gt,\n",
    "            'aff_gt': aff_gt,\n",
    "            # 'affine_boxes': affine_boxes,\n",
    "            # 'line_boxes': line_boxes,\n",
    "            # 'char_label': char_label\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        sample['char_gt'] = TR.resize(sample['char_gt'], (\n",
    "            int(self.image_size[1] / self.down_rate), int(self.image_size[2] / self.down_rate)))\n",
    "        sample['aff_gt'] = TR.resize(sample['aff_gt'], (\n",
    "            int(self.image_size[1] / self.down_rate), int(self.image_size[2] / self.down_rate)))\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d8141",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab8ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_with_bn_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, up=False):\n",
    "        super(Base_with_bn_block, self).__init__()\n",
    "        self.up = up\n",
    "        if up:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=int(kernel_size / 2))\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.up:\n",
    "            x = self.up(x)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class Base_down_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, times):\n",
    "        super(Base_down_block, self).__init__()\n",
    "\n",
    "        self.blocks = [Base_with_bn_block(in_channels, out_channels, 3)]\n",
    "        for i in range(times - 1):\n",
    "            self.blocks += [Base_with_bn_block(out_channels, out_channels, 3)]\n",
    "        self.blocks = nn.Sequential(*self.blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.blocks(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Base_up_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Base_up_block, self).__init__()\n",
    "        self.block1 = Base_with_bn_block(in_channels, out_channels * 2, 1, up=True)\n",
    "        self.block2 = Base_with_bn_block(out_channels * 2, out_channels, 3)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out = torch.cat([x1, x2], 1)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UP_VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UP_VGG, self).__init__()\n",
    "        self.layers = nn.Sequential(*[Base_down_block(3, 64, 2),\n",
    "                                      Base_down_block(64, 128, 2),\n",
    "                                      Base_down_block(128, 256, 3),\n",
    "                                      Base_down_block(256, 512, 3),\n",
    "                                      Base_down_block(512, 512, 3),\n",
    "                                      Base_down_block(512, 512, 3), ])\n",
    "\n",
    "        self.up_layers = nn.Sequential(*[Base_up_block(512 + 512, 256),\n",
    "                                         Base_up_block(512 + 256, 128),\n",
    "                                         Base_up_block(256 + 128, 64),\n",
    "                                         Base_up_block(128 + 64, 32)])\n",
    "\n",
    "        self.detector = nn.Sequential(*[Base_with_bn_block(32, 32, 3),\n",
    "                                        Base_with_bn_block(32, 32, 3),\n",
    "                                        Base_with_bn_block(32, 16, 3),\n",
    "                                        Base_with_bn_block(16, 16, 1)])\n",
    "\n",
    "        self.region = nn.Conv2d(16, 1, 1)\n",
    "        self.affinity = nn.Conv2d(16, 1, 1)\n",
    "\n",
    "        self.pooling = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for i in range(5):\n",
    "            x = self.layers[i](x)\n",
    "            x = self.pooling(x)\n",
    "            features.append(x)\n",
    "        x = self.layers[-1](x)\n",
    "        for index in range(4):\n",
    "            x = self.up_layers[index](features[-index - 1], x)\n",
    "        x = self.detector(x)\n",
    "        reg = self.region(x)\n",
    "        aff = self.affinity(x)\n",
    "        return reg, aff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f34e49",
   "metadata": {},
   "source": [
    "### Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591e7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_OHEM_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSE_OHEM_Loss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, output_imgs, target_imgs):\n",
    "        loss_every_sample = []\n",
    "        batch_size = output_imgs.size(0)\n",
    "        for i in range(batch_size):\n",
    "            output_img = output_imgs[i].view(1, -1)\n",
    "            target_img = target_imgs[i].view(1, -1)\n",
    "            positive_mask = (target_img > 0).float()\n",
    "            sample_loss = self.mse_loss(output_img, target_img)\n",
    "\n",
    "            positive_loss = torch.masked_select(sample_loss, positive_mask.byte())\n",
    "            negative_loss = torch.masked_select(sample_loss, 1 - positive_mask.byte())\n",
    "            num_positive = int(positive_mask.sum().data.cpu().item())\n",
    "\n",
    "            k = num_positive * 3\n",
    "            num_all = output_img.shape[1]\n",
    "            if k + num_positive > num_all:\n",
    "                k = int(num_all - num_positive)\n",
    "            if k < 10:\n",
    "                avg_sample_loss = sample_loss.mean()\n",
    "            else:\n",
    "                negative_loss_topk, _ = torch.topk(negative_loss, k)\n",
    "                avg_sample_loss = positive_loss.mean() + negative_loss_topk.mean()\n",
    "            loss_every_sample.append(avg_sample_loss)\n",
    "        return torch.stack(loss_every_sample, 0).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8678996",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bd764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data, please wait a moment...\n",
      "load data, please wait a moment...\n",
      "2021-05-17 23:59:26.264 finish load\n",
      "2021-05-17 23:59:26.265  training.........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelvan/.local/lib/python3.8/site-packages/torch/nn/functional.py:3454: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "<ipython-input-8-b2c35ca98824>:15: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  positive_loss = torch.masked_select(sample_loss, positive_mask.byte())\n",
      "<ipython-input-8-b2c35ca98824>:16: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  negative_loss = torch.masked_select(sample_loss, 1 - positive_mask.byte())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-18 00:04:19.799 0 999 218.6844322308898 133.71892590541393 84.96550659229979\n",
      "337 186 171\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1f032ea5b772>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_l\u001b[0m  \u001b[0;31m# + loss_cls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_size = (3, 640, 640)\n",
    "train_dataset = SynthText(image_size=image_size,\n",
    "                          random_rote_rate=30,\n",
    "                          transform=transforms.Compose([\n",
    "                              RandomCrop((480, 480)),\n",
    "                              Rescale((640, 640)),\n",
    "                              Random_change(0.5, 0.5, 0.5, 0.5, 0.5)]))\n",
    "\n",
    "train_dataLoader = DataLoader(train_dataset, 2, shuffle=True, num_workers=4,\n",
    "                              collate_fn=random_resize_collate)\n",
    "test_dataset = SynthText(image_size=image_size, istrain=False)\n",
    "\n",
    "test_dataLoader = DataLoader(test_dataset, 4, shuffle=False, num_workers=4)\n",
    "\n",
    "vgg = UP_VGG()\n",
    "vgg = vgg.to(\"cuda\")\n",
    "print(TicToc.format_time(), \"finish load\")\n",
    "\n",
    "optimizer = torch.optim.Adam(vgg.parameters(), lr=0.001)\n",
    "# crite = nn.MSELoss(reduction=\"mean\")\n",
    "# l1_crite = nn.SmoothL1Loss(reduction=\"mean\")\n",
    "# cls_crite = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "loss_fn = MSE_OHEM_Loss()\n",
    "loss_fn = loss_fn.to(\"cuda\")\n",
    "print(TicToc.format_time(), \" training.........\")\n",
    "\n",
    "for e in range(1):\n",
    "    # train\n",
    "    total_loss = 0.0\n",
    "    char_loss = 0.0\n",
    "    aff_loss = 0.0\n",
    "    b_total_loss = 0.0\n",
    "    b_char_loss = 0.0\n",
    "    b_aff_loss = 0.0\n",
    "    vgg.train()\n",
    "\n",
    "    for i, batch_data in enumerate(train_dataLoader):\n",
    "        image = batch_data[\"image\"].type(torch.FloatTensor) / 255 - 0.5\n",
    "        image = image.to(\"cuda\")\n",
    "        reg, aff = vgg(image)\n",
    "        predict_r = torch.squeeze(reg, dim=1)\n",
    "        predict_l = torch.squeeze(aff, dim=1)\n",
    "\n",
    "        targets_r = batch_data[\"char_gt\"].type(torch.FloatTensor)\n",
    "        targets_r = targets_r.to(\"cuda\")\n",
    "\n",
    "        targets_l = batch_data[\"aff_gt\"].type(torch.FloatTensor)\n",
    "        targets_l = targets_l.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_r = loss_fn(predict_r, targets_r)\n",
    "        loss_l = loss_fn(predict_l, targets_l)\n",
    "\n",
    "        loss = loss_r + loss_l  # + loss_cls\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        char_loss += loss_r.item()\n",
    "        aff_loss += loss_l.item()\n",
    "        b_total_loss += loss.item()\n",
    "        b_char_loss += loss_r.item()\n",
    "        b_aff_loss += loss_l.item()\n",
    "\n",
    "        if i % 1000 == 999:\n",
    "            print(TicToc.format_time(), e, i, b_total_loss, b_char_loss, b_aff_loss)\n",
    "            b_total_loss = 0.0\n",
    "            b_char_loss = 0.0\n",
    "            b_aff_loss = 0.0\n",
    "\n",
    "    print(\"Train \", TicToc.format_time(), e, total_loss, char_loss, aff_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
